{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install Necessary Packages"
      ],
      "metadata": {
        "id": "NG55YEQGCaby"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei_N_jlUvWDV",
        "outputId": "6f067c7e-1aac-47b0-993a-397e625f19a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install torch\n",
        "!pip -q install sentence_transformers\n",
        "!pip -q install faiss-cpu\n",
        "!pip -q install huggingface-hub\n",
        "!pip -q install pypdf\n",
        "!pip -q install accelerate\n",
        "!pip -q install llama-cpp-python\n",
        "!pip -q install git+https://github.com/huggingface/transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LangChain** is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis\n",
        "\n",
        "**PyTorch** is a machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella\n",
        "\n",
        "**SentenceTransformers** is a Python framework for state-of-the-art sentence, text and image embeddings. Install the Sentence Transformers library.\n",
        "\n",
        "**Faiss** is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. It is developed by Facebook AI Research.\n",
        "\n",
        "The H**ugging Face Hub** is a platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. The Hub works as a central place where anyone can explore, experiment, collaborate, and build technology with Machine Learning\n",
        "\n",
        "**pypdf** is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files. It can also add custom data, viewing options, and passwords to PDF files. pypdf can retrieve text and metadata from PDFs as well.\n",
        "\n",
        "**Accelerate** is a library that enables the same PyTorch code to be run across any distributed configuration by adding just four lines of code! In short, training and inference at scale made simple, efficient and adaptable.\n",
        "\n",
        "**llama-cpp-python** is a Python binding for llama.cpp.\n",
        "It supports inference for many LLMs models, which can be accessed on Hugging Face.\n",
        "\n",
        "**Transformers** provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n",
        "\n",
        "These models can be applied on:\n",
        "\n",
        "    üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, and text generation, in over 100 languages.\n",
        "    üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.\n",
        "    üó£Ô∏è Audio, for tasks like speech recognition and audio classification.\n",
        "\n",
        "Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.\n",
        "\n",
        "ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.\n",
        "\n",
        "ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other."
      ],
      "metadata": {
        "id": "Z7Nmov38_YVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Mistral 7B Model\n",
        "Get Link From Source"
      ],
      "metadata": {
        "id": "2uvC9ctS_P_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'LINK HERE'"
      ],
      "metadata": {
        "id": "PWB6gDlH3Z4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Necessary LangChain Functions\n"
      ],
      "metadata": {
        "id": "9L-ixdF4BT19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8D6s3uMHv-NG"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load PDF Files\n"
      ],
      "metadata": {
        "id": "AZpbtnf5BbjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fEXsAyTZxBu7"
      },
      "outputs": [],
      "source": [
        "#load pdf files\n",
        "loader = PyPDFDirectoryLoader(\"Data/\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMtudY08xzRO",
        "outputId": "a020e91a-7c2c-48c2-8ec0-e364fdb32011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\" \\n   Research Project : Transformer -based approach for bug identification, summarization  \\nand classification  \\n Software bug reports are crucial in software maintenance and evolution, with concise summaries considerably enhancing the efficacy of bug triggers and ultimately contributing to developing high- quality software products  [1, 3]. Due to the emergence of social media, there \\nis an exponential increase in the demand for developing various software applications targeting different application domains. Moreover, all the popular software applications, such as Bugzilla, Facebook, etc., constantly release new versions of the applications, making the software management and evolution process challenging. Recently, there has been an increase in the bugs reported by the end- user across various social media platforms for a particular \\napplication. For example, based on a study published in 2013, Bugzilla receives 135 bug reports daily, which might be increased now based on the recent usage and increase in the end -users \\npopulation.   Moreover, bug identification and resolution remedies are essential in time to retain the large pool of end- users  [2]. In contrast, the user gets frustrated and leaves or uninstalls the software \\napplication  [4]. Moreover, in the literature, automated approaches have been proposed using \\nmachine and deep learning to identify and classify bug reports. However, these approaches must be more generalized to the machine and deep learning algorithms' performance in mult iple \\ndatasets. Also, these approaches often produce poor summaries due to two primary limitations: the challenges in incorporating the domain- specific knowledge inherent in bug reports and the \\nlimitations of purely supervised learning in comprehending the comprehensive context of bug reports. We are in terested in proposing an improved bug identification and classification \\napproach. We are interested in extending this research in multiple directions. \\n1. Improve the performance of bug identification and classification by introducing customized transfer learning algorithms.   \\n2. Identify the performance of the proposed transfer learning algorithm on multiple data sets aiming at the generalization of the proposed approach.  \\n3. Many bug reports are submitted against popular software applications, which makes it challenging for software developers and vendors to provide in- time remedies. Also, the \\nthe bug reports submitted are lengthy, comprising many unimportant information. Ther efore, we aim to propose a transfer learning approach to summarize the bug reports \\nefficiently and simplify the job for developers and software vendors by restoring the software quality and user satisfaction.   \\n4. Another challenge is that many bug reports are submitted to the issue tracking system by the software developers and users; some of them are critical and need instant resolution and attention from the software vendors. Therefore, we propose an automated ap proach that identifies the bug's severity in the bug- tracking system using \\na transfer learning approach.  \\n5. The most concerning issue with machine, deep, and transfer learning algorithms for bug identification and classification tasks is their black -box nature, which restricts software \\nvendors from understanding the complex decision- making process. Therefore, we  are \\ninterested in introducing a novel explainability- based deep learning approach for \\nidentifying, classifying, and summarizing bug identification that would help software vendors and developers improve  the decision -making process.  \\n  \", metadata={'source': 'Data/Software_Explainability_Khan.pdf', 'page': 0}), Document(page_content=' Supervised by: Javed Ali Khan an d Muham mad Yaqoob  \\n \\n References  \\n \\n1. Khan JA, Liu L,Wen L. Requirements knowledge acquisition from online user forums. IET Softw. 2020;14(3):242- 253. \\n2. Ullah T, Khan JA, Khan ND, Yasin A, Arshad H. Exploring and mining rationale information for low -rating software applications. Soft Comput. 2023;27:1- 26. \\n3. Khan JA,Yasin A, Fatima R,VasanD,Khan AA, KhanAW.Valuating requirements arguments in the online user‚Äôs forum for requirements decision- making:  the CrowdRE -\\nVArg framework. Software: Practice and Experience. John Wiley & Sons Ltd; 2022. \\n4. Khan JA, Xie Y, Liu L, Wen L. Analysis of requirements -related arguments in user \\nforums. Proceeding of 2019 IEEE 27th International Requirements Engineering Conference (RE). IEEE; 2019:63- 74. \\n  ', metadata={'source': 'Data/Software_Explainability_Khan.pdf', 'page': 1}), Document(page_content='Machine Learning, Decision-making and Stochastic ControlThe ProjectWe are seeking applicants for a fully funded PhD in the areas of machine learning, decision-making, and stochastic control. Recent advancements in ArtiÔ¨Åcial Intelligence have resolved challenges once deemed insurmountable just a decade ago. The integration of machine learning, decision-making, and stochastic control is central to this breakthrough.This project will push the boundaries of Reinforcement Learning by investigating how agents can continuously learn and adapt over time; how they can autonomously develop and Ô¨Çexibly apply an ever-expanding repertoire of skills across various tasks; and what representations allow them to do this efÔ¨Åciently. Addressing these questions is crucial for creating AI systems that, despite limited computational resources, can sustain autonomous learning and adaptation in ever-changing environments.The selected candidate will have the opportunity to master and contribute to the cutting-edge techniques in deep reinforcement learning, incorporating principles from probabilistic machine learning, such as information theory, intrinsic motivation, and open-ended learning frameworks. The project will employ computer games as benchmarking tools and/or apply its Ô¨Åndings to robotic systems (in simulations or on real-world platforms), including manipulators, intelligent autonomous vehicles, and humanoid robots. This PhD project offers a unique chance to explore some of the most profound and fascinating questions in artiÔ¨Åcial intelligence today, providing the opportunity to make a signiÔ¨Åcant contribution to a Ô¨Åeld at the forefront of AI research.RequirementsWe are looking for a student who is motivated and passionate about ArtiÔ¨Åcial Intelligence. A background in computer science or mathematics, together with strong programming skills, are essential requirements. Experience in reinforcement learning, deep learning or robotics are desirable and will be considered a plus during the selection process. The applicant will be expected to disseminate her/his work publishing scientiÔ¨Åc articles and/or participating at international conferences. To be Ô¨Çuent in English is mandatory.ApplicationInterested applicants should contact Dr. Nicola Catenacci Volpi (n.catenacci-volpi@herts.ac.uk) to discuss the project, the PhD program at the University of Hertfordshire and details of the application process.', metadata={'source': 'Data/ML_Stochastic_Control_Catenacci1.pdf', 'page': 0}), Document(page_content='Large Language Models and Cybersecurity  \\n \\n \\nProject description  \\n \\nLarge language models (LLMs) are a type of artificial intelligence (AI) that are trained on \\nmassive datasets of text and code. They can now complete many complex text -based tasks \\nrapidly and effectively, including generating text, translating languages, an d writing different \\nkinds of creative content.  \\n \\nIn this work we would like to explore the interaction between LLMs and cybersecurity. LLMs \\ncan be applied in various ways to enhance cybersecurity . For example, LLMs are capable of \\nanaly sing vast amounts of textual data, including forums, blogs, and news articles, to identify \\nemerging cyber threats and trends.  They can also  automate the generation of security \\ndocumentation and reports, helping organizations communicate effectively about their \\nsecurity posture.  On the other hand, w hile LLMs becoming increasi ngly popular, they pose a \\nnumber of security risks. The OWASP foundation identifies ten common security \\nvulnerabilities that needs to be considered for developing LLMs ‚Äô applications .  \\n \\nWithin the context, h ere is two exemplary  topics that a PhD applicant may like to consider . \\n \\nTopic 1: Data leakage and privacy in use of Large Language Models  \\n \\nWith this topic  we are going to focus on the security risk associated with data leakage and \\nprivacy. For example, an LLM might learn from your prompts and offer that information to \\nothers who query for related things. Another example is that personally identifiable \\ninfor mation (PII) is used in training a language model which might unintentionally generate \\noutputs that reveal aspects of the PII. We plan to investigate a new way of sanitising \\nsensitive information and developing security policies to mitigate this. We conduc t an \\nexperiment by developing an LLM application and evaluating our security models with \\nrespect to how effective on preventing data leakage for the application.  \\n \\n \\nTopic 2: Leveraging Large Language Models for generating access control models  \\n \\nAccess control policies (ACPs) are typically part of security requirements, often written in \\nnatural language. ACPs articulate strict rules describing how access is managed, who may \\naccess which resources, and under what conditions. For instance, a doctor can change a \\npatient‚Äôs record in the healthcare system, but the nurse can only view the patient‚Äôs record. \\nThese ACPs are needed to be translated into a formal representation (e.g. attribute -based \\naccess control (ABAC) model) which is then implemented as an  access control mechanism \\n(service) in computer systems to enforce the security controls.  \\n \\nIn this work we would like to explore how to leverage LLMs to extract essential policy \\nelements from ACP sentences and how to use these policy elements to generate a particular \\nmodel that fits within a context in which the ACP sentences come from. We will define a set ', metadata={'source': 'Data/LLMs_Cybersecurity_Chen.pdf', 'page': 0}), Document(page_content='of criteria or properties that the generated model must satisfy , and run experiments to \\nevaluate the degree of satisfaction of the properties.  \\n \\n \\nCandidate profile  \\n \\nThe ideal candidate should have a first or upper -second class degree in Computer \\nScience/Cybersecurity/Mathematics (or equivalent overseas qualification), and/or a merit \\nMaster‚Äôs degree (or equivalent experience/qualifications). Prior scientific publications are \\nparticularly desirable bu t not essential. You should demonstrate a solid theoretical \\nbackground and excellent software development skills. Strong commitment to reaching \\nresearch excellence and achieving assigned objectives is required, as well as an  ability to \\nwork in a collaborative environment.  \\n \\n \\nSupervision Team  \\n \\nDr. Liang Chen  \\n \\nDr. Alexios Mylonas  \\n \\n \\n    \\n        \\n \\n \\n31/01/2024  ', metadata={'source': 'Data/LLMs_Cybersecurity_Chen.pdf', 'page': 1}), Document(page_content='Exploring Large Language Models for Personalized Content Generation in \\nVR/AR Environment  \\nWe invite applications from candidates with backgrounds in Virtual Reality/Augmented Reality \\n(VR/AR) technologies, Artificial Intelligence (AI), Machine Learning, or Computer Vision.  \\nPhD Topic Summary  \\nThis PhD research focuses on the integration of Large Language Models (LLMs), and emerging Virtual \\nReality (VR) and Augmented Reality (AR) technologies, for example,  Meta Quest 3 and Apple Vision. \\nThe project aims to create highly personalized, dynamic, and interactive content within VR and AR \\nenvironments. By harnessing the capabilities of LLMs  in conjunction with the strengths of VR/AR  \\ntechnologies , this research seeks to enhance user interaction and content personalization in virtual \\nsettings, offering groundbreaking improvements in realism, engagement, and user experience.  \\nBackground  \\nThe rapid advancement in VR and AR technologies has opened up new possibilities for immersive \\nexperiences. However, creating dynamic and personalized content that adapts in real -time to user \\ninteractions remains a challenge. The integration with the natural language understanding and \\ngeneration capabilities of LLMs, holds the potential to overcome these challenges . This research \\nproposes a novel approach by combining these technologies to address the current limitations in \\npersonalization and interaction within VR and AR environments.  \\nAims of this PhD  \\nThe primary aims of this PhD research are:  \\n‚Ä¢ To develop an innovative framework that integrates LLMs for enhancing personalized content \\ngeneration in VR and AR environments.  \\n‚Ä¢ To develop the fine-tuning a Custom Large Language Model specifically for VR/AR applications, \\nenhancing its ability to generate personalized and context -aware content that resonates with \\nusers in specific domains.  \\n‚Ä¢ To evaluate the impact of this integration on user experience, including personalization, \\nengagement, and satisfaction, through comprehensive user studies and performance analysis.  ', metadata={'source': 'Data/LLMs_VR_Zheng.pdf', 'page': 0}), Document(page_content='‚Ä¢ To contribute to the academic and practical understanding of integrating with LLMs in VR and AR \\nsettings, addressing technical challenges such as scalability, real -time interaction, adaptability, \\nand ethical considerations.  \\n \\nContact : For informal enquiries about this PhD, please contact :  \\nDr Yongjun Zheng,  y.zheng20 @herts.ac.uk  \\n \\nReferences  : \\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P ., Neelakantan, A., Shyam, P ., \\nSastry, G., Askell, A. and Agarwal, S., 2020. Language models are few -shot learners. Advances in \\nneural information processing systems, 33, pp.1877 -1901.  \\nLaValle, S.M., Center, E.G., Ojala, T., Pouke, M., Prencipe, N., Sakcak, B., Suomalainen, M., Timperi, \\nK.G. and Weinstein, V., 2023. From Virtual Reality to the Emerging Discipline of Perception \\nEngineering. Annual Review of Control, Robotics, and Autonomous Systems, 7.  ', metadata={'source': 'Data/LLMs_VR_Zheng.pdf', 'page': 1})]\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Files into Chunks"
      ],
      "metadata": {
        "id": "MPgE_fALBfk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "T1L27WlvyJIu"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=20)\n",
        "\n",
        "text_chunks = text_splitter.split_documents(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jq5TiVcyiu2",
        "outputId": "37376acd-a2ec-4712-d3f3-6afcb34b5784"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o8aXL-Ryp9e",
        "outputId": "456dd33e-ea53-4e98-d05e-5c3b48cb47eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Supervised by: Javed Ali Khan an d Muham mad Yaqoob  \\n \\n References  \\n \\n1. Khan JA, Liu L,Wen L. Requirements knowledge acquisition from online user forums. IET Softw. 2020;14(3):242- 253. \\n2. Ullah T, Khan JA, Khan ND, Yasin A, Arshad H. Exploring and mining rationale information for low -rating software applications. Soft Comput. 2023;27:1- 26. \\n3. Khan JA,Yasin A, Fatima R,VasanD,Khan AA, KhanAW.Valuating requirements arguments in the online user‚Äôs forum for requirements decision- making:  the CrowdRE -\\nVArg framework. Software: Practice and Experience. John Wiley & Sons Ltd; 2022. \\n4. Khan JA, Xie Y, Liu L, Wen L. Analysis of requirements -related arguments in user \\nforums. Proceeding of 2019 IEEE 27th International Requirements Engineering Conference (RE). IEEE; 2019:63- 74.', metadata={'source': 'Data/Software_Explainability_Khan.pdf', 'page': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "text_chunks[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialise Embeddings"
      ],
      "metadata": {
        "id": "LheQJUdvBq6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "M7oKKdTPyxax"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings for each of the Text Chunk"
      ],
      "metadata": {
        "id": "BGb0KX_-BvU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MJbn_hjzznhm"
      },
      "outputs": [],
      "source": [
        "vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Model"
      ],
      "metadata": {
        "id": "-6bPSUW9B6_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9Y5Va538RDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm = LlamaCpp(\n",
        "    streaming = True,\n",
        "    model_path=\"/content/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "    temperature=0.75,\n",
        "    top_p=1,\n",
        "    verbose=True,\n",
        "    n_ctx=4096\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0fsqtREeF2d"
      },
      "source": [
        "### Initiase QA Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4Vpb_w-i94Th"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read User Query"
      ],
      "metadata": {
        "id": "XjNsQEVgCGP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8DWiBe3cENZB"
      },
      "outputs": [],
      "source": [
        "query = \"bug identification done by which approch\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run User Query"
      ],
      "metadata": {
        "id": "ubW8PMRUCJgu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "mdFYMQfR_gzI",
        "outputId": "3bfaaa6e-9f65-4c9a-bc23-0eae6f2156ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2845.63 ms\n",
            "llama_print_timings:      sample time =      81.64 ms /   143 runs   (    0.57 ms per token,  1751.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =  658619.58 ms /  1448 tokens (  454.85 ms per token,     2.20 tokens per second)\n",
            "llama_print_timings:        eval time =   98718.94 ms /   143 runs   (  690.34 ms per token,     1.45 tokens per second)\n",
            "llama_print_timings:       total time =  758438.50 ms /  1591 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The proposed approach is not specified in the given context, but it mentions an interest in extending this research in multiple directions. Some of these directions are 1) Improve the performance of bug identification and classification by introducing customized transfer learning algorithms, 2) Identify the performance of the proposed transfer learning algorithm on multiple data sets aiming at the generalization of the proposed approach, 3) Propose a transfer learning approach to summarize the bug reports efficiently and simplify the job for developers and software vendors by restoring the software quality and user satisfaction, and 4) An automated approach that identifies the bug's severity in the bug- tracking system using a transfer learning approach.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl_4JdUatnTQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "  user_input = input(f\"Input Prompt: \")\n",
        "  if user_input == 'exit':\n",
        "    print('Exiting')\n",
        "    sys.exit()\n",
        "  if user_input == '':\n",
        "    continue\n",
        "  result = qa({'query': user_input})\n",
        "  print(f\"Answer: {result['result']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1abzXV9n5Wzh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}